{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                     # for dataframes' manipulation\n",
    "from pandas import DataFrame            # for creating dataframes\n",
    "import numpy as np                      # for arrays\n",
    "\n",
    "from itertools import chain\n",
    "\n",
    "from collections import Counter         # for counting elements \n",
    "from datetime import datetime           #for actual date\n",
    "import re                               # !!! relativní Novinka - regular expressions\n",
    "from time import sleep                  # for sleeping (slowing down) inside a function\n",
    "import random                           # for random number (sleeping)\n",
    "import math                             # Round float\n",
    "import time                             # Time measuring\n",
    "import itertools                        # for unlisting nested lists\n",
    "import sys\n",
    "import openpyxl\n",
    "\n",
    "##### Scraping ############\n",
    "import requests                         # for robots check\n",
    "from bs4 import BeautifulSoup           # for parsing\n",
    "from selenium import webdriver          # for browsers control\n",
    "import json                             # for Requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 = Scraping ################################################################################################################################\n",
    "\n",
    "def get_soup_elements(typ_obchodu = \"prodej\", typ_stavby = \"byty\", pages = 1):  \n",
    "    \n",
    "    browser = webdriver.Chrome()\n",
    "    \n",
    "    ##########################################\n",
    "    # 1. Volba Prodej/Pronájem, Byty/Domy,                 --Aukce/Bez Aukce (jen pro Prodeje) zatím nechávám být, cpe se mi to doprostřed url\n",
    "    ##########################################   \n",
    "    \n",
    "    url_x = r\"https://www.sreality.cz/hledani\"             \n",
    "    url = url_x + \"/\" +  typ_obchodu + \"/\" +  typ_stavby\n",
    "\n",
    "    ##########################################\n",
    "    # 2. načtení webu\n",
    "    ##########################################\n",
    "    \n",
    "    browser.get(url)    # (url).text ??\n",
    "    sleep(random.uniform(1.0, 1.5))\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(innerHTML,'lxml') # \"parser\" ??\n",
    "    \n",
    "    elements = []    \n",
    "    \n",
    "    for link in soup.findAll('a', attrs={'href': re.compile(\"^/detail/\")}):       # !!!!!!!!!!!!!!!!! změněno, protože H2 neobsahovalo všechny věci, jen nadpisek.\n",
    "        link = link.get('href')   \n",
    "        elements.append(link)     \n",
    "    elements = elements[0::2]   \n",
    "\n",
    "    ##########################################\n",
    "    # 3. zjištění počtu listů - mělo by být optional, ale nevadí\n",
    "    ##########################################\n",
    "    records = soup.find_all(class_ ='numero ng-binding')[1].text\n",
    "    records = re.split(r'\\D', str(records))                         \n",
    "    records = \",\".join(records).replace(\",\", \"\")\n",
    "    records = int(records)\n",
    "    max_page = math.ceil(records / 20)   \n",
    "    print(\"----------------\")\n",
    "    print(\"Scrapuji: \" + str(typ_obchodu) + \" \" + str(typ_stavby))\n",
    "    print(\"Celkem inzerátů: \" + str(records))\n",
    "    print(\"Celkem stránek: \" + str(max_page))\n",
    "    \n",
    "    ##########################################\n",
    "    # 4. nastavení počtu stránek  -mělo být víc promakané\n",
    "    ##########################################\n",
    "    if pages == 999:      # (NE)Speciální případ, chci všechny inzeráty - standardně tu bude asi kolem 600 stránek max, takže 999 je volné k použití\n",
    "        pages = max_page\n",
    "    \n",
    "    print(\"Scrapuji (pouze) \" + str(pages) + \" stran.\")\n",
    "    print(\"----------------\")\n",
    "    \n",
    "    ##########################################\n",
    "    # 5. Scrapping zbylých listů - naštěstí v jednom okně\n",
    "    ##########################################    \n",
    "    \n",
    "    for i in range(pages-1):   \n",
    "        i = i+2\n",
    "        \n",
    "        sys.stdout.write('\\r'+ \"Strana \" + str(i-1) + \" = \" + str(round(100*(i-1)/(pages), 2)) + \"% progress. Zbývá cca: \" + str(round(random.uniform(3.4, 3.8)*(pages-(i-1)), 2 )) + \" sekund.\")    # Asi upravím čas, na rychlejším kabelu v obýváku je to občas i tak 3 sec :O\n",
    "\n",
    "        url2 = url + \"?strana=\" + str(i)\n",
    "        browser.get(url2)\n",
    "\n",
    "        sleep(random.uniform(1.0, 1.5))\n",
    "\n",
    "        innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "        soup2 = BeautifulSoup(innerHTML,'lxml') \n",
    "        \n",
    "        elements2 = []\n",
    "        \n",
    "        for link in soup2.findAll('a', attrs={'href': re.compile(\"^/detail/prodej/\")}):  \n",
    "            link = link.get('href') \n",
    "            elements2.append(link)  \n",
    "   \n",
    "        elements2 = elements2[0::2]  \n",
    "        \n",
    "        elements = elements + elements2     # tyto se už můžou posčítat, naštěstí, řpedtím než z nich budeme dělat elems = prvky třeba jména\n",
    "\n",
    "    \n",
    "    browser.quit()   \n",
    "    \n",
    "    return elements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  2 = Získání URLS ###############################################################################################################################\n",
    "\n",
    "def elements_and_ids(x):\n",
    "    \n",
    "    elements = pd.DataFrame({\"url\":x})\n",
    "\n",
    "    def get_id(x):\n",
    "        x = x.split(\"/\")[-1]\n",
    "        return x\n",
    "\n",
    "    #elements[\"url_id\"] = elements[\"url\"].apply(get_id)\n",
    "    \n",
    "    len1 = len(elements)\n",
    "    #Přidáno nově, v tuto chvíli odmažu duplikáty a jsem v pohodě a šetřím si čas dál.\n",
    "    elements = elements.drop_duplicates(subset = [ \"url\"], keep = \"first\", inplace = False)   \n",
    "    len2 = len(elements)                                                                             \n",
    "                                                                                                      \n",
    "    print(\"-- Vymazáno \" + str(len1-len2) + \" záznamů kvůli duplikaci.\")\n",
    "    return elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametry:\n",
    "# \"prodej\"/ \"pronájem\"\n",
    "# \"byty\"/\"domy\"\n",
    "# pages = 1- X, případně 999 = Všechny strany !\n",
    "\n",
    "def scrap_all(typ_obchodu = \"prodej\", typ_stavby = \"byty\", pages = 1):\n",
    "    \n",
    "    # Scrapni data - hezky komunikuje = cca 50 min\n",
    "    data = get_soup_elements(typ_obchodu = typ_obchodu, typ_stavby = typ_stavby, pages = pages)\n",
    "    print( \"1/8 Data scrapnuta, získávám URLs.\")\n",
    "    \n",
    "    # 2 = Získání URLS\n",
    "    data = elements_and_ids(data)\n",
    "    data.to_excel(r\"a1_URLs_prodej_byty.xlsx\")\n",
    "    print( \"2/8 Získány URL, nyní získávám Souřadnice, Ceny a Popis - několik minut...\")\n",
    "    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Scrapuji: prodej byty\n",
      "Celkem inzerátů: 20626\n",
      "Celkem stránek: 1032\n",
      "Scrapuji (pouze) 25 stran.\n",
      "----------------\n",
      "Strana 24 = 96.0% progress. Zbývá cca: 3.63 sekund..1/8 Data scrapnuta, získávám URLs.\n",
      "-- Vymazáno 1240 záznamů kvůli duplikaci.\n",
      "2/8 Získány URL, nyní získávám Souřadnice, Ceny a Popis - několik minut...\n"
     ]
    }
   ],
   "source": [
    "data = scrap_all(pages=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['null','detail', 'prodej','byt','velikost','lokace','id']] = data.url.str.split(\"/\", expand = True)\n",
    "data = data.drop(['url','null', 'detail','prodej','byt','id'], axis=1)\n",
    "data.to_csv('sreality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('sreality.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedTable",
     "evalue": "relation \"users\" does not exist\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUndefinedTable\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\petre\\Desktop\\python\\sreality.ipynb Cell 9\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39msreality.csv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     \u001b[39m# Notice that we don't need the csv module.\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39mnext\u001b[39m(f) \u001b[39m# Skip the header row.\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     cur\u001b[39m.\u001b[39;49mcopy_from(f, \u001b[39m'\u001b[39;49m\u001b[39musers\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m conn\u001b[39m.\u001b[39mcommit()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/petre/Desktop/python/sreality.ipynb#X15sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m conn\u001b[39m.\u001b[39mclose()\n",
      "\u001b[1;31mUndefinedTable\u001b[0m: relation \"users\" does not exist\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "conn = psycopg2.connect(host='localhost',\n",
    "port = '5432',\n",
    "user = 'postgres',\n",
    "password = '159357lol',\n",
    "dbname = 'postgres')\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "cur.execute('DROP TABLE IF EXISTS sreality')\n",
    "\n",
    "create_script= \"CREATE TABLE IF NOT EXISTS sreality (ID INT,Velikost VARCHAR(255), Lokace VARCHAR(255))\"\n",
    "cur.execute(create_script)\n",
    "\n",
    "with open('sreality.csv', 'r') as f:\n",
    "    # Notice that we don't need the csv module.\n",
    "    next(f) # Skip the header row.\n",
    "    cur.copy_from(f, 'sreality', sep=',')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "cur.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
